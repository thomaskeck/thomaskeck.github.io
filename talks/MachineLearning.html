<!doctype html>
<html>
	<head>
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="mobile-web-app-capable" content="yes">
    <link rel="manifest" href="manifest.json">
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

		<title>Machine Learning Lecture</title>

		<meta name="description" content="An overview of Machine Learning">
		<meta name="author" content="Thomas Keck">

		<link rel="stylesheet" href="../reveal.js/css/reveal.css">
		<link rel="stylesheet" href="../reveal.mod/css/theme/current.css">
		<link rel="stylesheet" href="../reveal.js/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? '../reveal.js/css/print/pdf.css' : '../reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

	</head>
	<body>
		<div class="reveal">
			<div class="slides" style="height: 100%">
        <!-- Overview -->
				<section style="height: 100%">
				<section>
          <h1>Machine Learning: An Introduction</h1>

					<p>
          Thomas Keck (<a href="mailto:thomas.keck2@kit.edu">thomas.keck2@kit.edu</a>)
					</p>
        </section>
				
        <section>
          <h3>Japenese vs. Chinese</h3>

					<p class="fragment" style="font-size: 5em;">
		      电
					</p>
					
          <p class="fragment">
		      Chinese
					</p>
        </section>
        
        <section>
          <h3>Training / Fitting</h3>


          <p style="color: var(--blue-color);">
          Japanese (hiragana)
          </p>
					<p style="font-size: 2em;">
			    ま ち ね ら に ご
					</p>
          
          <p style="color: var(--red-color);">
          Chinese (kanji)
          </p>
					<p style="font-size: 2em;">
			    电 买 开 东 车 红 马
					</p>
        </section>

        <section>
          <h3>Application / Inference</h3>
          
					<div style="float: left; width: 50%">
          <p class="fragment" style="font-size: 2em;">
          の
          </p>
          <p class="fragment" style="color: var(--blue-color);">
          Japanese (hiragana)
          </p>
          <p class="fragment" style="font-size: 2em;">
          る
          </p>
          <p class="fragment" style="color: var(--blue-color);">
          Japanese (hiragana)
          </p>
          <p class="fragment" style="font-size: 2em;">
			    热
          </p>
          <p class="fragment" style="color: var(--red-color);">
          Chinese (kanji)
          </p>
          </div>
					<div style="float: right; width: 50%">
          <p class="fragment" style="font-size: 2em;">
			    时
          </p>
          <p class="fragment" style="color: var(--red-color);">
          Chinese (kanji)
          </p>
          <p class="fragment" style="font-size: 2em;">
			    な
          </p>
          <p class="fragment" style="color: var(--blue-color);">
          Japanese (hiragana)
          </p>
          <p class="fragment" style="font-size: 2em;">
			    陸
          </p>
          <p class="fragment" style="color: var(--red-color);">
          Chinese (kanji)
          </p>
          </div>
					
        </section>
		
        <section style="height: 100%">
          <div style="height: 20vh"></div>
          <p>
          Take a moment to appreciate what you just did
          </p>
          <div style='height: 5vh'></div>
          <b>
          <p  class="fragment" style="color: var(--green-color);">
          Let's build a machine that can do this!
          </p>
          </b>
        </section>
		
        <section style="height: 100%">
          
          <div style="display: flex; width: 100%;">
          <div class="fragment" style="float: left; width: 50%; height: 35vmin">
            <img src="images/go.jpg">
          </div>
          <div class="fragment" style="float: right; width: 50%; height: 35vmin">
            <img src="images/higgs.png">
          </div>
          </div>
          <br>
          <div style="display: flex; width: 100%;">
          <div class="fragment" style="float: left; width: 50%; height: 35vmin">
            <img src="images/stock.jpg">
          </div>
          <div class="fragment" style="float: right; width: 50%; height: 35vmin">
            <img src="images/supermarkt.jpg">
          </div>
          </div>

        </section>

				<section style="height: 100%">
				<h3>Workflow</h3>
              <div class="fig-container"
                   data-fig-id="workflow"
                   data-file="animations/workflow.html" style="width: 100%; height: 100%"></div>
				</section>
				
				<section style="height: 100%">
				<h3>Multivariate Classification</h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/dataset.html" style="width: 100%; height: 100%"></div>
				</section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: var(--blue-color)'>Decision Tree</div> & <div style='color: var(--red-color)'>Model Complexity</div></h2>
				</section>
        <section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>Decision Tree (Inference)</div></h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/decision_tree.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>Decision Tree (Fitting)</div></h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/decision_tree_fitting.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>Decision Tree (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Classifies using a number of consecutive rectangular cuts</li>
            <li>Each cut locally maximizes a separation gain measure</li>
            <li>Signal probability given by the purity in each leaf</li>
            <li>Interpretable (white box) model</li>
          </ul>
          </div>
          <div style="width: 60%; height: 40vh; float: right">
            <img data-src="images/tree_classifier.png" style="background:none; border:none; box-shadow:none;">
            <br />
            Misclassification Rate: 16%
          </div>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import tree
            dt = tree.DecisionTreeClassifier(max_depth=4)
            dt.fit(X, y)
            dt.predict(X)
          </code></pre>
				</section>
        
				<section data-background-image="images/tree_visualization_30.png" data-background-size="60%" style="height: 100%">
          <h3><div style='color: var(--red-color)'>Model Complexity</div></h3>
          <div style="width: 50%; height: 50vh; float: left" class="fragment">
            <div style="color: var(--green-color)">Training Dataset</div><br />
            <img data-src="images/full_contour_train.png" style="background:var(--light-background-color); border:none; box-shadow:none;" class="white_style_image">
            <br />
            Misclassification Rate: 0%
          </div>
          <div style="width: 50%; height: 50vh; float: right" class="fragment">
            <div style="color: var(--green-color)">Independent Test Dataset</div><br />
            <img data-src="images/full_contour_test.png" style="background:var(--light-background-color); border:none; box-shadow:none;" class="white_style_image">
            <br />
            Misclassification Rate: 21%
          </div>
				</section>
        
        <section>
          <h3><div style='color: var(--red-color)'>Overfitting</div></h3>
          <ul style="font-size: 3vmin">
            <li>Model is too complex</li>
            <li>Statistical fluctuations in the training data dominate predictions</li>
            <li>Model does not generalize → poor performance on new data</li>
            <li>Need to check for this on an independent test dataset!</li>
          </ul>

          <center>
          <div style="width: 60%; height: 50vh">
            <img data-src="images/full_contour_test.png" style="background:none; border:none; box-shadow:none;" class="white_style_image">
          </div>
          </center>
				</section>
        
        <section>
          <h3><div style='color: var(--red-color)'>Underfitting</div></h3>
          <ul style="font-size: 3vmin">
            <li>Model is too simple</li>
            <li>Relevant aspects of the data are ignored</li>
          </ul>

          <center>
          <div style="width: 60%; height: 50vh">
            <img data-src="images/simple_contour_test.png" style="background:none; border:none; box-shadow:none;" class="white_style_image">
          </div>
          </center>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>Training vs. Test Error</div></h3>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/decision_tree_depth.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section>
          <h3><div style='color: var(--red-color)'>Bias-Variance Dilemma</div></h3>
          <ul style="font-size: 3vmin">
            <li>Bias due to wrong modeling of the data (underfitting)</li>
            <li>Variance due to sensitivity to statistical fluctuations (overfitting)</li>
            <li>Irreducible error due to noise in the problem itself</li>
          </ul>
          <div style='height: 5vh'></div>
          $$ \mathrm{E} \left\lbrack (y- \widehat{f}(\vec{x}))^2 \right\rbrack = \mathrm{Bias} \left\lbrack \widehat{f}(\vec{x}) \right\rbrack^2 + \mathrm{Var} \left\lbrack \widehat{f}(\vec{x}) \right\rbrack + \mathrm{Var} \left\lbrack y \right\rbrack $$

          <div style="width: 100%; height: 30vh">
            <img data-src="images/bias_variance.png" style="background:none; border:none; box-shadow:none;" class="black_style_image">
          </div>
				</section>
        
        <section>
          <h3><div style='color: var(--red-color)'>Model Complexity</div></h3>
          <b>Number of Degrees of freedom (NDF) of the model<br /> (≈ number of parameters)</b><br />

          <ul style="font-size: 3vmin">
            <li><div style='color: var(--green-color)'>Input dataset</div></li>
            <ul>
              <li>Reduce dimensionality</li>
              <li>Higher statistic</li>
            </ul>
            <li><div style='color: var(--green-color)'>Hyperparameters (control NDF)</div></li>
            <ul>
              <li>E.g. depth of the tree</li>
              <li>Optimized using search-algorithm</li>
            </ul>
            <li><div style='color: var(--green-color)'>Regularization (reduce effective NDF)</div></li> 
            <ul>
              <li>E.g. Include tree structure in separation gain measure</li>
              <li>Ensemble methods</li>
            </ul>
          </ul>

				</section>
        
        <section>
          <h3><div style='color: var(--red-color)'>Model Complexity</div> <br />(All you have to know)</h3>
				
          <div style="height: 10vh"></div>
          <b><div style="color: var(--green-color)" class="fragment">Always test on an independent test dataset in the end!</div></b>

        </section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: var(--blue-color)'>Boosted Decision Tree</div> & <div style='color: var(--red-color)'>Ensemble Methods</div></h2>
				</section>
				
        <section>
          <h3><div style='color: var(--red-color)'>Ensemble Methods</div></h2>

          <div style='height: 20vh'></div>
          <b>Average many simple models to obtain a robust complex model</b>
          <div style='height: 5vh'></div>
        
          $$ F\left( \vec{x} \right) = \sum_m \gamma_m f_m(\vec{x}) $$

				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--red-color)'>Boosting</div></h2>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/boosting.html" style="width: 100%; height: 100%"></div>
				</section>
        <section>
          <h3><div style='color: var(--red-color)'>Boosting</div></h2>
          <div style="width: 35%; height: 50vh; float: left;">
            <img src="images/boosting_scheme.png" style="background:none; border:none; box-shadow:none;" class="black_style_image">
          </div>
          <div style="width: 65%; height: 50vh; float: right;">
            <div style="height: 5vh"></div>
            <ul style="font-size: 3vmin">
              <li>Reweight events w.r.t current prediction</li>
              <li>Individual classifiers are simple (weak-learners)</li>
              <li>Focus on events near the optimal separation hyper-plane</li>
              <li>Loss function L is crucial</li>
              <ul>
                <li>Least square → Regression</li>
                <li>Binomial deviance → GradientBoost Classification</li>
                <li>Exponential loss → AdaBoost classification</li>
              </ul>
            </ul>
          </div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--red-color)'>Bagging</div></h2>
              <div class="fig-container"
                   data-fig-id="dataset"
                   data-file="animations/bagging.html" style="width: 100%; height: 100%"></div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--red-color)'>Bagging</div></h2>
          <div style="width: 100%; height: 20vh;">
            <img src="images/bagging_scheme.png" style="background:none; border:none; box-shadow:none;" class="black_style_image">
          </div>

            <div style="height: 5vh"></div>
            <ul style="font-size: 3vmin">
              <li>Use only a fraction of events / features per classifier</li>
              <li>Robustness against statistical fluctuations</li>
              <li>Embarrassingly parallel</li>
              <li>Sampling method is crucial:</li>
              <ul>
                <li><div style='color: var(--green-color); display: inline'>Bagging:</div> random events with replacements</li>
                <li><div style='color: var(--green-color); display: inline'>Pasting:</div> random events without replacement</li>
                <li><div style='color: var(--green-color); display: inline'>Random Subspaces:</div> random features</li>
              </ul>
            </ul>
				</section>
        
        <section>
          <h3><div style='color: var(--blue-color)'>Stochastic Boosted Decision Tree (Summary)</div></h3>

          <div style="display: flex">
          <div style="width: 40%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Good out-of-the-box performance</li>
            <li>Robust against over-fitting</li>
            <li>Supports classification and regression</li>
            <li>Widely used in HEP</li>
          </ul>
          </div>
          <div style="width: 60%; height: 40vh; float:right">
            <img data-src="images/forest_classifier.png" style="background:none; border:none; box-shadow:none;" class="white_style_image">
            <br />
            Misclassification Rate: 14.5%
          </div>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import ensemble
            bdt = ensemble.GradientBoostingClassifier(subsample=0.5,
                                                      max_depth=3,
                                                      n_estimators=50) 
            bdt.fit(X, y)
            bdt.predict(X)
          </code></pre>
				</section>
        
        <section>
          <h3><div style='color: var(--red-color)'>Further Ensemble Methods</div></h2>

          <div style='height: 5vh'></div>
          <ul style="font-size: 3vmin">
            <center><b style='color: var(--green-color)'>Categorization</b></center>
            <li>Divide feature-space into sub-spaces</li>
            <li>Different behavior of the data in the chosen subspaces</li>
            <li>e.g. train separate classifiers for Barrel and Endcap</li>
            <div style='height: 5vh'></div>
          
            <center><b style='color: var(--green-color)'>Combination</b></center>
            <li>Combine different classifiers</li>
            <li>Different regularization methods learn different aspects of the data</li>
            <li>e.g. combine neural network, BDT and SVM</li>
          </ul>

				</section>

        </section>
				
        <section style="height: 100%">
				<section>
          <h2><div style='color: var(--blue-color)'>Support Vector Machine</div> & <div style='color: var(--red-color)'>Kernel Trick</div></h2>
				</section>
        <section>
          <h3><div style='color: var(--blue-color)'>Support Vector Machine</div></h3>
          <div style="width: 50%; height: 50vmin; float: left;" class="fragment">
            <img data-src="images/svm-hyperplane.png" style="background:none; border:none; box-shadow:none;" class="black_style_image"><br>
            <small><a href="https://en.wikipedia.org/wiki/Support_vector_machine#/media/File:Svm_max_sep_hyperplane_with_margin.png">Wikipedia</a></small>
          </div>
          <div style="width: 50%; height: 50vmin; float: right;" class="fragment">
            <img data-src="images/linear_svm_classifier.png" style="background:none; border:none; box-shadow:none;" class="white_style_image">
            <br />
            Misclassification Rate: 24%
          </div>
				</section>
				<section>
          <h3><div style='color: var(--red-color)'>Kernel Trick</div></h3>
          <ul style="font-size: 3vmin">
            <li>SVM Algorithm depends only on scalar product!</li>
            <li>Replace scalar product with an arbitrary kernel function</li>
            <li>Solves problem in implicitly high-dimensional space</li>
          </ul>

          <div style='height: 5vh'></div>
          $$ \max g(c_1, \dots, c_n) $$
          $$ g(c_1, \dots, c_n)= \sum_i c_i - \frac{1}{2} \sum_i \sum_j y_i c_i (\vec{x}_i \cdot \vec{x}_j) y_j c_j$$
				</section>
        <section>
          <h3><div style='color: var(--red-color)'>Kernel Trick</div></h3>
          <div style="width: 50%; height: 50vmin; float: left;" class="fragment">
            <div style="color: var(--green-color)">Polynomial Kernel<br /> $k(x_i, x_j) ) = (x_i \cdot x_j)^d$</div><br />
            <img data-src="images/poly_svm_classifier.png" style="background:none; border:none; box-shadow:none;" class="white_style_image">
            <br />
            Misclassification Rate: 19%
          </div>
          <div style="width: 50%; height: 50vmin; float: right;" class="fragment">
            <div style="color: var(--green-color)">Gaussian Kernel<br /> $k(x_i, x_j) ) = \exp(-\gamma ||x_i - x_j||^2)$</div><br />
            <img data-src="images/rbf_svm_classifier.png" style="background:none; border:none; box-shadow:none;" class="white_style_image">
            <br />
            Misclassification Rate: 15%
          </div>
				</section>
        <section>
          <h3><div style='color: var(--blue-color)'>Support Vector Machine (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 40%; height: 40vmin; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Maximum margin classifier</li>
            <li>Quadratic problem: can be solved efficiently in $O(N^2)$</li>
            <li>Optimal for linearly separable problems</li>
            <li>Kernel trick allows solving of non-linear problems</li>
            <li>Solution depends only on the support-vectors</li>
          </ul>
          </div>
          <div style="width: 60%; height: 40vmin; float:right">
            <img data-src="images/rbf_svm_classifier.png" style="background:none; border:none; box-shadow:none;" class="white_style_image">
            <br />
            Misclassification Rate: 15%
          </div>
          </div>

          <div style='height: 10vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import svm
            svc = svm.SVC(kernel='rbf')
            svc.fit(X, y)
            svc.predict(X)
          </code></pre>
				</section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: var(--blue-color)'>Artificial Neural Networks</div> & <div style='color: var(--red-color)'>Universal Function Approximator</div></h2>
				</section>

        <section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>Artificial Neural Network</div></h3>
              <div class="fig-container"
                   data-fig-id="neural_network"
                   data-file="animations/neural_network.html" style="width: 100%; height: 100%"></div>
        </section>
				
        <section  style="height: 100%">
          <h3><div style='color: var(--red-color)'>Universal Function Approximator</div></h3>
  
          <div style='height: 2vh'></div>
          $$f(\vec{x}) = \sigma \left(\sum_h w_{oh} \sigma_h \left( \sum_i w_{hi} x_i \right) \right)$$
          <div style='height: 1vh'></div>
          <b>→ can approximate any reasonable function $f: \mathrm{R}^\mathrm{N} \rightarrow [0, 1]$</b>
          <div style='height: 10vh'></div>

          Usually visualized as a network
          <div style="display: flex; height: 50%">
          <div style="width: 50%; float: left; height: 100%">
          <div style='height: 7vh'></div>
          <table>
            <tr><td>Link</td><td> $\hat{=}$</td><td>$w_{ij}$</td></tr>
            <tr><td>Neuron</td><td> $\hat{=}$</td><td>$\sigma \left( \sum \dots \right)$</td></tr>
          </table>
          </div>
          <div style="width: 50%; float: right; height: 100%">
          <div class="fig-container"
               data-fig-id="forward_neural_network"
               data-file="animations/forward_neural_network.html" style="width: 100%; height: 100%"></div>
          </div>
          </div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>Activation Functions</div></h3>
          <div style='height: 2vh'></div>
            $$\sigma (\underbrace{\sum w x}_{a})$$
          <div style='height: 2vh'></div>
          <ul style="font-size: 3vmin">
           <li><div style='color: var(--blue-color); display: inline'>Desirable properties</div>: Nonlinear, Differentiable, Monotonic, Smooth</li>
           <li><div style='color: var(--blue-color); display: inline'>Examples for the hidden layer</div>:</li>
              <ul>
                <li>sigmoid $\frac{1}{1+e^{-a}}$: <div style='color: var(--red-color); display: inline'>not zero-centered</div>, <div style='color: #f05050; display: inline'>saturates</div> $\rightarrow$ don't use this</li>
                <li>$\tanh(a)$: <div style='color: var(--green-color); display: inline'>zero-centered</div>, <div style='color: var(--red-color); display: inline'>saturates</div> $\rightarrow$ better than sigmoid</li>
                <li>ReLU $\max(0, a)$: <div style='color: var(--green-color); display: inline'>constant gradient</div>, <div style='color: #50f050; display: inline'>fast</div>, <div style='color: var(--red-color); display: inline'>can die out</div></li>
                <li>PReLU $\max(0, a) - \beta \max(0, -a)$:  <div style='color: var(--green-color); display: inline'>constant gradient</div>, <div style='color: #50f050; display: inline'>fast</div>, <div style='color: var(--red-color); display: inline'>additional parameter</div> </li>
            </ul>
          </ul>
          <div class="fig-container"
               data-fig-id="neural_network"
               data-file="animations/activation_functions.html" style="width: 100%; height: 100%"></div>
        </section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--red-color)'>Backpropagation of Error</div></h3>
  
          <div style='height: 2vh'></div>
          $$ \Delta w  = - \eta \frac{\mathrm{d}\mathcal{L}}{\mathrm{d}w} $$
          <div style='height: 1vh'></div>
          <b>→ choose weights so that they minimize a loss-function</b>
          <div style='height: 2vh'></div>
          $ \mathcal{L} = H\left(y, f(\vec{x})\right) = $ <div style='color: var(--blue-color); display: inline'>$-y \ln (f(\vec{x}))$</div><div style='color: var(--red-color); display: inline'>$ - (1-y) \ln (1 - f(\vec{x}))$</div> $\quad (\textrm{with }\ y = 0, 1)$
          <div class="fig-container"
               data-fig-id="neural_network"
               data-file="animations/classification_loss_functions.html" style="width: 100%; height: 100%"></div>
				</section>
        
        
        <section>
          <h3><div style='color: var(--blue-color)'>Artificial Neural Network (Summary)</div></h3>
          <div style="display: flex">
          <div style="width: 50%; height: 40vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Universal function approximator</li>
            <li>Adjust weights to minimize loss-function</li>
            <li>Fast and small model</li>
            <li>Fitting can be challenging</li>
            <li>Ubiquitous in all modern ML applications</li>
          </ul>
          </div>
          <div style="width: 50%; height: 40vh; float:right;">
            <img data-src="images/mpl_classifier.png" style="background:none; border:none; box-shadow:none;" class="white_style_image"><br/>
            Misclassification Rate: 15.5%
          </div>
          </div>

          <div style='height: 5vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import neural_network
            ann = neural_network.MLPClassifier(activation='tanh',
                                               hidden_layer_sizes=(3,))
            ann.fit(X, y)
            ann.predict(X)
          </code></pre>
				</section>
				</section>
				
        <section style="height: 100%">
				<section>
          <h2><div style='color: var(--blue-color)'>Artificial Neural Networks</div> & <div style='color: var(--red-color)'>Stochastic Gradient Descent</div></h2>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--red-color)'>Stochastic Gradient Descent</div></h3>

          <ol style="font-size: 3vmin">
            <li>Feed $N$ samples to the network ($N \hat{=} $ batch-size $\rightarrow$ <div style="color: var(--green-color); display: inline">stochastic</div>)</li>
            <li>Calculate the <div style="color: var(--green-color); display: inline">gradient</div> of the average loss with respect to each weight using the chain-rule of analysis</li>
            <li>Adjust the weights in the opposite direction (<div style="color: var(--green-color); display: inline">descent</div>) with a small step-size (learning-rate) $\eta$</li>
            <li>Repeat until convergence</li>
          </ol>
          
          <div class="fig-container"
               data-fig-id="sgd"
               data-file="animations/stochastic_gradient_descent.html" style="width: 100%; height: 60%"></div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--red-color)'>Stochastic Gradient Descent</div></h3>

          <ol style="font-size: 3vmin">
            <li>Feed $N$ samples to the network ($N \hat{=} $ batch-size $\rightarrow$ <div style="color: var(--green-color); display: inline">stochastic</div>)</li>
            <li>Calculate the <div style="color: var(--green-color); display: inline">gradient</div> of the average loss with respect to each weight using the chain-rule of analysis</li>
            <li>Adjust the weights in the opposite direction (<div style="color: var(--green-color); display: inline">descent</div>) with a small step-size (learning-rate) $\eta$</li>
            <li>Repeat until convergence</li>
          </ol>
        
          <div style="height: 10vmin"></div>
          <div style="text-align: left">
          <div style="color: var(--green-color);">
            Many more advanced variants of Stochastic Gradient Descent exists
          </div>
            <ul>
              <li>Older: L-BFGS, AdaGrad, AdaDelta, RMSProb</li>
              <li>ADAM: Adaptive moment estimation <a href="https://arxiv.org/abs/1412.6980">D. P. Kingma, J. Ba (12/2014)</a></li>
              <li>NADAM: ADAM + Nesterov momentum </li>
            </ul>
          <div style="height: 10vmin"></div>

          <div style="color: var(--green-color);">
            How should you choose the associated hyper-parameters?
          </div>
            <ul>
              <li>Learning Rate and Learning Rate Schedule</li>
              <li>Batch-Size</li>
              <li>Momentum Term</li>
            </ul>
          </div>
				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>Learn-Rate Schedule</div></h3>
          
          <div class="fig-container"
               data-fig-id="sgd"
               data-file="animations/initial_gradient_descent.html" style="width: 100%; height: 100%"></div>
        </section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--red-color)'>Learn-Rate vs. Batch-Size vs. Momentum</div></h3>
  
          <div style='height: 2vh'></div>
          $$ \Delta w_t  = - \underbrace{\eta}_{\textrm{Learn-Rate}} \cdot \underbrace{ \frac{\mathrm{d}}{\mathrm{d}w} \frac{1}{N} \sum_i^N \mathcal{L}_i}_{\textrm{Gradient averaged over Batch-Size}} + \underbrace{m \cdot \Delta w_{t-1}}_{\textrm{Momentum term}} $$
          <div style='height: 5vh'></div>
          <p>
          Initial noisy optimization phase is similar to simulated annealing<br> $\rightarrow$ explored region is determined by the noise scale $g$ 
          </p>
          <div style='height: 2vh'></div>
          $$ g \sim \frac{\eta}{N (1-m)} $$

          <a href="https://arxiv.org/abs/1711.00489">S. L. Smith, P. Kindermans, C. Ying, Q. V. Le (02/2018)</a>
          
          <div style='height: 5vh'></div>
          If you increase the Batch-Size you must increase the Learn-Rate!

				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--red-color)'>Regularization:</div><div style='color: var(--blue-color)'>Early Stopping</div></h3>
              <p>
              Idea: Prevent overfitting by stopping the training before convergence
              </p>
              <p style="color: var(--green-color)">
              Very effective and simple!
              </p>
              <div class="fig-container"
                   data-fig-id="neural_network"
                   data-file="animations/early_stopping.html" style="width: 100%; height: 100%"></div>
        </section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--red-color)'>Regularization:</div><div style='color: var(--blue-color)'>$L_1$ and $L_2$ Penalty Terms</div></h3>
              <p>
              Idea: Prevent overfitting by penalize large weights<br>
              Optimal Brain Damage: Forget unimportant stuff<br>
              $$\mathcal{L} \rightarrow \mathcal{L} + L_{\textrm{Penalty}}$$
              </p>
             
          <div style="text-align: left">
              <div style="height: 5vmin"></div>
              <div class="fragment">
              <div style="color: var(--green-color)">
              $$L_2 = \beta \sum_i  w_i^2 $$
              </div>
              <ul>
                <li>Requires careful choice of $\beta$</li>
                <li>Also called Ridge leads to dense representations</li>
                <li>Equivalent to <div style='color: var(--green-color); display: inline'>weight-decay</div> for Stochastic Gradient Descent</li>
              </ul>
              </div>

              <div style="height: 5vmin"></div>
              <div class="fragment">
              <div style="color: var(--green-color)">
              $$L_1 = \alpha \sum_i | w_i | $$
              </div>
              <ul>
                <li>Requires careful choice of $\alpha$</li>
                <li>Also called LASSO leads to sparse representations</li>
              </ul>
              
              </div>
              </div>
              
        </section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: var(--blue-color)'>Generative Models</div> & <div style='color: var(--red-color)'>Neyman-Pearson Lemma</div></h2>
				</section>
        
        <section>
          <h3><div style='color: var(--red-color)'>Neyman-Pearson Lemma</div></h3>
          
          <blockquote>
          On the Problem of the most Efficient Tests of Statistical Hypotheses
          <br>
          By J. Neyman and E. S. Pearson
          </blockquote>
          </pre>

          $$ f\left(\vec{x}\right) = \frac{\mathrm{PDF}\left( \vec{x} | \mathrm{S} \right)}{\mathrm{PDF}\left( \vec{x} | \mathrm{B} \right)} $$

          <p style='color: var(--green-color)'>
          Most powerful test at a given significance level to distinguish between two simple hypotheses (signal or background)
          </p>
				</section>
        
        <section>
          <h3><div style='color: var(--red-color)'>Problem solved? No!</div></h3>
          
          <p>
          Signal and Background PDF are usually unknown
          </p>

          <ul style="font-size: 3vmin">
            <li>High dimensional $\rightarrow$ cannot be sampled due to the <b>curse of dimensionality</b></li>
            <li>Multiple sources for signal and background</li>
            <li>Mislabelled training data / Simulation uncertainties</li>
          </ul>
          <br /> 
          <img data-src="images/curse_of_dimensionality.png" style="background:none; border:none; box-shadow:none; height:30vh;">

				</section>
        
        <section>
          <h3><div style='color: var(--red-color)'>Solution: Approximate Neyman-Pearson Lemma</div></h3>
          
          <div style="display: flex">
          <div style="width: 50%; height: 10vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li style="color: var(--green-color)">Neyman-Pearson Lemma</li>
          </ul>
          </div>
          <div style="width: 50%; height: 10vh; float:right">
            $$ f\left(\vec{x}\right) = \frac{\mathrm{PDF}\left( \vec{x} | \mathrm{S} \right)}{\mathrm{PDF}\left( \vec{x} | \mathrm{B} \right)} $$
          </div>
          </div>
          
          <div style="display: flex" class="fragment">
          <div style="width: 50%; height: 20vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li style="color: var(--green-color)">Discriminative Models</li>
            <ul style="font-size: 3vmin">
              <li>(Boosted) Decision Trees</li>
              <li>Support Vector Machines</li>
              <li>Artificial Neural Networks</li>
            </ul>
          </ul>
          </div>
          <div style="width: 50%; height: 20vh; float:right">
            <div style="height: 5vh"></div>
            $$ f\left(\vec{x}\right) \approx \frac{\mathrm{PDF}\left( \vec{x} | \mathrm{S} \right)}{\mathrm{PDF}\left( \vec{x} | \mathrm{B} \right)} $$
          </div>
          </div>
          
          <div style="display: flex" class="fragment">
          <div style="width: 50%; height: 20vh; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li style="color: var(--green-color)">Generative Models</li>
            <ul style="font-size: 3vmin">
              <li>Analytical approx. (LDA, QDA)</li>
              <li>Kernel density estimator</li>
              <li>Gaussian mixture model</li>
            </ul>
          </ul>
          </div>
          <div style="width: 50%; height: 20vh; float:right">
            <div style="height: 5vh"></div>
            $$ f\left(\vec{x} | \mathrm{S}\right) \approx \mathrm{PDF}\left( \vec{x} | \mathrm{S} \right) $$
            $$ f\left(\vec{x} | \mathrm{B}\right) \approx \mathrm{PDF}\left( \vec{x} | \mathrm{B} \right) $$
          </div>
          </div>
          
				</section>
        
        <section>
          <h3><div style='color: var(--blue-color)'>Linear Discriminant Analysis</div></h3>
          <div style="display: flex">
          <div style="width: 50%; height: 50vmin; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Assumes conditional PDFs are normally distributed</li>
            <li>Assumes identical covariances</li>
            <li>Equivalent to Fisher’s discriminant</li>
            <li>Requires only means and covariances of sample</li>
            <li>Separating hyperplane is linear</li>
            <br />
          $ f(x) = x^{\mathrm{T}} \cdot \Sigma^{-1} (\mu_{\mathrm{S}} - \mu_{\mathrm{B}}) $
          </ul>
          </div>
          <div style="width: 50%; height: 50vmin; float: right;">
            <img data-src="images/lda_classifier.png" style="background:none; border:none; box-shadow:none;" class="white_style_image">
            <br/>
            Misclassification Rate: 24%
          </div>
          </div>

          <div style='height: 5vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import lda
            ld = lda.LDA()
            ld.fit(X, y)
            ld.predict(X)
          </code></pre>
				</section>

        <section>
          <h3><div style='color: var(--blue-color)'>Quadratic Discriminant Analysis</div></h3>
          <div style="display: flex">
          <div style="width: 50%; height: 50vmin; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Assumes conditional PDFs are normally distributed</li>
            <li>Requires only means and covariances of sample</li>
            <li>Separating hyperplane is quadratic</li>
          <p style="font-size: 2.5vmin">
          $ f(x) = \frac{\sqrt{2 \pi | \Sigma_{\mathrm{B}} |} \exp\left( - \frac{1}{2} \left(x - \mu_{\mathrm{S}}\right)^{\mathrm{T}} \Sigma^{-1}_{\mathrm{S}} \left(x - \mu_{\mathrm{S}}\right)  \right) }{ \sqrt{2 \pi | \Sigma_{\mathrm{S}} |}  \exp\left( - \frac{1}{2} \left(x - \mu_{\mathrm{B}}\right)^{\mathrm{T}} \Sigma^{-1}_{\mathrm{B}} \left(x - \mu_{\mathrm{B}}\right)  \right)  }$
          </p>
          </ul>
          </div>
          <div style="width: 50%; height: 50vmin; float:right">
            <img data-src="images/qda_classifier.png" style="background:none; border:none; box-shadow:none;" class="white_style_image"><br />
            Misclassification Rate: 21%
          </div>
          </div>

          <div style='height: 5vh'></div>
          <b>SKLearn Example</b>
          <pre><code class='python' data-trim>
            from sklearn import qda
            qd = qda.QDA()
            qd.fit(X, y)
            qd.predict(X)
          </code></pre>
				</section>
        
        <section>
          <h3><div style='color: var(--blue-color)'>Kernel Density Estimator</div></h3>
          <div style="display: flex">
          <div style="width: 50%; height: 50vmin; float: left; align-items: center; display: flex">
          <ul style="font-size: 3vmin">
            <li>Every training sample is replaced with a small gaussian sphere</li>
            <li>Bandwith (variance of gaussian) is key</li>
            <li>Works well for low dimensions</li>
          <br />
          </ul>
          </div>
          <div style="width: 50%; height: 50vmin; float:right">
            <img data-src="images/kde_classifier.png" style="background:none; border:none; box-shadow:none;" class="white_style_image">
            <br />
            Misclassification Rate: 16%
          </div>
          </div>

          <div style='height: 5vh'></div>
          <b>SciPy Example</b>
          <pre><code class='python' data-trim>
            from scipy.stats import gaussian_kde
            signal = gaussian_kde(signal_samples)
            background = gaussian_kde(background_samples)
          </code></pre>
				</section>
        </section>
				
				<section style="height: 100%">
				<section>
          <h2><div style='color: var(--blue-color)'>Extensions</div> & <div style='color: var(--red-color)'>Multivariate Regression</div></h2>
				</section>
				<section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>(Generalized) Linear Regression</div></h3>
          <ul  style="font-size: 3vmin">
            <li>Linear Regression of Base-Functions</li>
            <li>$y = \beta_0 + \beta_1 \phi_1(x_1) + \dots \beta_n \phi_n(x_n)$</li>
            <li>Fitted with least-square method</li>
          </ul>
          
          <div style="width: 100%; height: 100%">
          <div class="fig-container"
               data-fig-id="linear_regression"
               data-file="animations/linear_regression.html" style="width: 100%; height: 100%"></div>
          </div>

				</section>
				
        <section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>(Boosted) Decision Trees</div></h3>
          <ul  style="font-size: 3vmin">
              <li>Various different algorithms exists</li>
              <li>Easiest: calculate average and right of each possible split points</li>
              <li>Minimize $\left(y - \bar{y}_{\mathrm{L}}\right)^2 + \left(y - \bar{y}_{\mathrm{R}}\right)^2$</li>
          </ul>
          
          <div style="width: 100%; height: 100%">
          <div class="fig-container"
               data-fig-id="decision_tree_regression"
               data-file="animations/decision_tree_regression.html" style="width: 100%; height: 100%"></div>
          </div>

				</section>
        
        <section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>Support Vector Regression</div></h3>
          <ul  style="font-size: 3vmin">
              <li>Search for maximum-margin hyper-band incorporating all data-points</li>
          </ul>
          <br /> 
          <div style="width: 50%; height: 50vh; float: left;" class="fragment">
            <img data-src="images/svm-hyperplane.png" style="background:none; border:none; box-shadow:none; height: 70%" class="black_style_image"><br>
            <small><a href="https://en.wikipedia.org/wiki/Support_vector_machine#/media/File:Svm_max_sep_hyperplane_with_margin.png">Wikipedia</a></small>
          </div>
          <div style="width: 50%; height: 50vh; float: right;" class="fragment">
            <img data-src="images/svr.png" style="background:none; border:none; box-shadow:none; height: 70%" class="black_style_image"><br>
          <small style="width: 100%">
            <a href="https://www.researchgate.net/figure/Visualization-of-support-vector-regression-framework_fig1_272024714">
              M. Alamaniotis and V. Agarwal: Fuzzy Integration of Support Vector Regressor Models for Anticipatory Control of Complex Energy Systems
            </a>
          </small>
          </div>

				</section>
				
        <section style="height: 100%">
          <h3><div style='color: var(--blue-color)'>Artificial Neural Networks</div></h3>
          <ul>
            <li>Neural Networks are still <b>universal</b> function approximators</li>
            <li>Output activation function: linear</li>
            <li>Loss Function: Square $\left((f(\vec{x}) - y\right)^2$ or Absolute $\left|(f(\vec{x}) - y\right|$</li>
          </ul>
          
          <div style='height: 1vh'></div>
          $$f(\vec{x}) = \sum_h w_{oh} \sigma_h \left( \sum_i w_{hi} x_i \right)$$
          <div style='height: 1vh'></div>
          <b>→ can approximate any reasonable function $f: \mathrm{R}^\mathrm{N} \rightarrow \mathrm{R}$</b>
          
          <div class="fig-container"
               data-fig-id="neural_network"
               data-file="animations/regression_loss_functions.html" style="width: 100%; height: 100%"></div>

				</section>
        
        <section>
          <h3><div style='color: var(--red-color)'>Summary</div></h3>
          <div style='height: 10vh'></div>

          <p style='color: var(--green-color)'>
          All concepts we encountered are still valid
          </p>
          <ul>
            <li>Model Complexity - Bias Variance Tradeoff</li>
            <li>Ensemble Methods - Boosting und Bagging</li>
            <li>SVM: Kernel Trick</li>
            <li>ANN: Stochastic Gradient Descent</li>
          </ul>

				</section>
        </section>
				
        <section style="height: 100%">
				<section>
          <h2><div style='color: var(--blue-color)'>Outlook</div> & <div style='color: var(--red-color)'>References</div></h2>
				</section>
				<section>
          <h3><div style='color: var(--blue-color)'>Outlook</div></h3>

          <div style='height: 10vh'></div>
          There will be a second lecture on <div style='color: var(--green-color); display: inline'>Deep Learning</div> after a short break<br />
          <div style='height: 4vh'></div>
          There will be workshop on <div style='color: var(--green-color); display: inline'>Tensorflow</div> in the afternoon
				</section>
				<section data-markdown>
          <h3><div style='color: var(--red-color)'>References</div></h3>

            <textarea data-template>
                An (incomplete) list of interesting books:

                  - Christopher M. Bishop. Pattern Recognition and Machine Learning
                  - Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning.
                  - J. Han, M. Kamber, J. Pei. Data Mining: Concepts and Techniques 
                  - O. Behnke, K. Kröninger, G. Scott, T. Schörner-Sadenius. Data Analysis in High Energy Physics: A Practical Guide to Statistical Methods
                  - [I. Goodfellow, Y. Bengio, A. Courville. Deep Learning (Adaptive Computation and Machine Learning)](http://www.deeplearningbook.org/)
                  - [R. S. Sutton, and A. G. Barto. Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html)


                You can find a list of research publications I enjoyed reading [here](https://thomaskeck.github.io/articles/)
            </textarea>
				</section>
        </section>
			</div>
		</div>

		<script src="../reveal.js/lib/js/head.min.js"></script>
		<script src="../reveal.js/js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
        controlsTutorial: false,
        center: false,
        transition: 'fade',
        history: true,
        width: '80%',
        height: '100%',
        math: {
            mathjax: '../reveal.mod/plugin/MathJax/MathJax.js'
        }, 
				dependencies: [
          { src: '../reveal.mod/js/d3.v4.min.js' },
          { src: '../reveal.mod/plugin/reveal.js-d3js-plugin/d3js.js' },
					{ src: '../reveal.js/plugin/markdown/marked.js' },
					{ src: '../reveal.js/plugin/markdown/markdown.js' },
					{ src: '../reveal.js/plugin/notes/notes.js', async: true },
					{ src: '../reveal.js/plugin/math/math.js', async: true },
					//{ src: '../reveal.js/plugin/highlight/highlight.js', async: false, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
